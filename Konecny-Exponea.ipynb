{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exponea Data Analytics Challenge \n",
    "\n",
    "**Author:** Štefan Konečný\n",
    "\n",
    "**Email:** konecny.mokum@gmail.com\n",
    "\n",
    "**Date:** 15 February 2017\n",
    "\n",
    "### Preview of the Data\n",
    "\n",
    "Let us have a brief look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Dependent-Company Status</th>\n",
       "      <th>year of founding</th>\n",
       "      <th>Age of company in years</th>\n",
       "      <th>Internet Activity Score</th>\n",
       "      <th>Short Description of company profile</th>\n",
       "      <th>Industry of company</th>\n",
       "      <th>Focus functions of company</th>\n",
       "      <th>Investors</th>\n",
       "      <th>Employee Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Percent_skill_Data Science</th>\n",
       "      <th>Percent_skill_Business Strategy</th>\n",
       "      <th>Percent_skill_Product Management</th>\n",
       "      <th>Percent_skill_Sales</th>\n",
       "      <th>Percent_skill_Domain</th>\n",
       "      <th>Percent_skill_Law</th>\n",
       "      <th>Percent_skill_Consulting</th>\n",
       "      <th>Percent_skill_Finance</th>\n",
       "      <th>Percent_skill_Investment</th>\n",
       "      <th>Renown score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company1</td>\n",
       "      <td>Success</td>\n",
       "      <td>No Info</td>\n",
       "      <td>No Info</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Video distribution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>operation</td>\n",
       "      <td>KPCB Holdings|Draper Fisher Jurvetson (DFJ)|Kl...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company2</td>\n",
       "      <td>Success</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Research|Marketing|Crowdfunding</td>\n",
       "      <td>Marketing, sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.823529412</td>\n",
       "      <td>21.76470588</td>\n",
       "      <td>10.88235294</td>\n",
       "      <td>2.941176471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Company3</td>\n",
       "      <td>Success</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>455.0</td>\n",
       "      <td>Event Data Analytics API</td>\n",
       "      <td>Analytics|Cloud Computing|Software Development</td>\n",
       "      <td>operations</td>\n",
       "      <td>TechStars|Streamlined Ventures|Amplify Partner...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.846153846</td>\n",
       "      <td>17.09401709</td>\n",
       "      <td>9.401709402</td>\n",
       "      <td>0</td>\n",
       "      <td>2.777777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company4</td>\n",
       "      <td>Success</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>The most advanced analytics for mobile</td>\n",
       "      <td>Mobile|Analytics</td>\n",
       "      <td>Marketing &amp; Sales</td>\n",
       "      <td>Michael Birch|Max Levchin|Sequoia Capital|Keit...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company5</td>\n",
       "      <td>Success</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>496.0</td>\n",
       "      <td>The Location-Based Marketing Platform</td>\n",
       "      <td>Analytics|Marketing|Enterprise Software</td>\n",
       "      <td>Marketing &amp; Sales</td>\n",
       "      <td>DFJ Frontier|Draper Nexus Ventures|Gil Elbaz|A...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Name Dependent-Company Status year of founding  \\\n",
       "0     Company1                  Success          No Info   \n",
       "1     Company2                  Success             2011   \n",
       "2     Company3                  Success             2011   \n",
       "3     Company4                  Success             2009   \n",
       "4     Company5                  Success             2010   \n",
       "\n",
       "  Age of company in years  Internet Activity Score  \\\n",
       "0                 No Info                     -1.0   \n",
       "1                       3                    125.0   \n",
       "2                       3                    455.0   \n",
       "3                       5                    -99.0   \n",
       "4                       4                    496.0   \n",
       "\n",
       "     Short Description of company profile  \\\n",
       "0                      Video distribution   \n",
       "1                                     NaN   \n",
       "2                Event Data Analytics API   \n",
       "3  The most advanced analytics for mobile   \n",
       "4   The Location-Based Marketing Platform   \n",
       "\n",
       "                              Industry of company Focus functions of company  \\\n",
       "0                                             NaN                  operation   \n",
       "1          Market Research|Marketing|Crowdfunding           Marketing, sales   \n",
       "2  Analytics|Cloud Computing|Software Development                 operations   \n",
       "3                                Mobile|Analytics          Marketing & Sales   \n",
       "4         Analytics|Marketing|Enterprise Software          Marketing & Sales   \n",
       "\n",
       "                                           Investors  Employee Count  \\\n",
       "0  KPCB Holdings|Draper Fisher Jurvetson (DFJ)|Kl...             3.0   \n",
       "1                                                NaN             NaN   \n",
       "2  TechStars|Streamlined Ventures|Amplify Partner...            14.0   \n",
       "3  Michael Birch|Max Levchin|Sequoia Capital|Keit...            45.0   \n",
       "4  DFJ Frontier|Draper Nexus Ventures|Gil Elbaz|A...            39.0   \n",
       "\n",
       "       ...       Percent_skill_Data Science Percent_skill_Business Strategy  \\\n",
       "0      ...                                0                               0   \n",
       "1      ...                      8.823529412                     21.76470588   \n",
       "2      ...                      3.846153846                     17.09401709   \n",
       "3      ...                                0                               0   \n",
       "4      ...                                0                               0   \n",
       "\n",
       "  Percent_skill_Product Management Percent_skill_Sales  Percent_skill_Domain  \\\n",
       "0                                0                   0                     0   \n",
       "1                      10.88235294         2.941176471                     0   \n",
       "2                      9.401709402                   0           2.777777778   \n",
       "3                                0                   0                     0   \n",
       "4                                0                   0                     0   \n",
       "\n",
       "  Percent_skill_Law Percent_skill_Consulting Percent_skill_Finance  \\\n",
       "0                 0                        0                     0   \n",
       "1                 0                        0                     0   \n",
       "2                 0                        0                     0   \n",
       "3                 0                        0                     0   \n",
       "4                 0                        0                     0   \n",
       "\n",
       "  Percent_skill_Investment  Renown score  \n",
       "0                        0             0  \n",
       "1                        0             8  \n",
       "2                        0             9  \n",
       "3                        0             5  \n",
       "4                        0             6  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies 472\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "startup_df = pd.read_csv(\"Startup_Data.csv\")\n",
    "display(startup_df.head())\n",
    "\n",
    "print \"Number of companies \"+str(startup_df.index.size)\n",
    "\n",
    "startup_df[[\"Company_Name\", \"Dependent-Company Status\"]].groupby( [\"Dependent-Company Status\"] ).count()\n",
    "\n",
    "import IPython.core.display as di\n",
    "\n",
    "# This line will hide code by default when the notebook is exported as HTML\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "# This line will add a button to toggle visibility of code blocks, for use with the HTML export version\n",
    "#di.display_html('''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>''', raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 472 different companies and 116 varaibles describing each.\n",
    "\n",
    "Suprisingly there are almost twice as many (305) sucessful companies as failed ones (167). This is of course **VERY SUSPICIOUS** and likely an indication of a synthetic data set. In real life most companies fail.\n",
    "\n",
    "More importantly, I have to be very careful to **AVOID OVERFITTING** since I have much more data on successful companies the on failed ones.\n",
    "\n",
    "### My approach\n",
    "\n",
    "1. Divide companies in sucessfull(S) and failed(F) ones\n",
    "1. Create normalized histograms for each variable\n",
    "1. Detect signficicant differences between histograms for S and F companies \n",
    "\n",
    "Because the there are much more S companies then F companies I will use normalized histograms for comparing variables. I make sure that:\n",
    "\n",
    "1. Bin boundaries are the same for S and F\n",
    "1. Each bins contains the percentage and not a count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "success_df = startup_df[startup_df[\"Dependent-Company Status\"]==\"Success\"].reset_index()\n",
    "failed_df = startup_df[startup_df[\"Dependent-Company Status\"]==\"Failed\"].reset_index()\n",
    "\n",
    "df_sf = (success_df,failed_df)\n",
    "\n",
    "def normalize_double_hist(data, bins = 20, h_range = None):\n",
    "    if (h_range == None):\n",
    "        min_val = min(data[0].min(),data[1].min())\n",
    "        max_val = max(data[0].max(),data[1].max())\n",
    "    else:\n",
    "        min_val = h_range[0]\n",
    "        max_val = h_range[1]\n",
    "    \n",
    "    # if there are both + and - values center on 0, 0 has often a special meaning \n",
    "    # so it sholdn't be in a centre of a bin    \n",
    "    if (min_val * max_val) < 0:\n",
    "        max_val = max(abs(min_val),max_val)\n",
    "        min_val = -max_val\n",
    "        \n",
    "    #get histograms\n",
    "    hist0, bin_edges = np.histogram(data[0], bins, range =  (min_val,max_val))\n",
    "    hist1, _ = np.histogram(data[1], bins, range =  (min_val,max_val))\n",
    "    \n",
    "    #normalize histograms\n",
    "    n_hist0 = hist0.astype(np.float32) / hist0.sum()\n",
    "    n_hist1 = hist1.astype(np.float32) / hist1.sum()\n",
    "    \n",
    "    return (bin_edges,n_hist0,n_hist1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing variables\n",
    "\n",
    "The function above works on numerical data only. Many variables need some pre processing.\n",
    "\n",
    "1. **Numerical variables**\n",
    "   * Can ocassionally contain a string (e.g. 'No value')\n",
    "   * If there are both negative and positive value, 0 should be a border of histogram bins\n",
    "\n",
    "2. **Categorical variables**\n",
    "   * Fall into a small number of categories (e.g. 'yes'/'no')\n",
    "   * Each histogram bin corresponds to one histogram bin   \n",
    "   * The values can be case sensitive (e.g. 'yes'/'Yes'/'YES')\n",
    "\n",
    "3. **Other variables**\n",
    "   * Unique strings ('Company_Name')\n",
    "   * Set of values ('Industry of company')\n",
    "\n",
    "We can automatically divide variables into those categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 97, 100, 101, 112, 116]\n",
      "[12, 26, 39, 40]\n",
      "[5, 10, 11, 15, 23, 66, 72, 74, 88, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115]\n",
      "[1, 6, 7, 8, 9, 13, 14, 16, 62]\n"
     ]
    }
   ],
   "source": [
    "cat_var = []\n",
    "lower_var = []\n",
    "num_var = []\n",
    "other_var = []\n",
    "\n",
    "def split_variables(index, data = df_sf, cv = cat_var, lv = lower_var, nv = num_var, ov =other_var):\n",
    "    s_col = data[0].iloc[:,index].dropna()\n",
    "    f_col = data[1].iloc[:,index].dropna()\n",
    "    \n",
    "    t_size = float(s_col.size+f_col.size) \n",
    "    \n",
    "    #unique vals\n",
    "    unique_vals = np.append(s_col.unique(),f_col.unique())\n",
    "    unique_vals = np.unique(unique_vals)\n",
    "    \n",
    "    u_size = float(unique_vals.size)\n",
    "    \n",
    "    #probably categorical\n",
    "    if ((u_size / t_size) < 0.05):\n",
    "        cv += [index]\n",
    "        \n",
    "        #try cat to lower\n",
    "        l_vals = pd.Series(unique_vals).apply(lambda x: str(x).lower())\n",
    "        l_vals = np.unique(l_vals)\n",
    "        l_size = float(l_vals.size)\n",
    "        \n",
    "        #if cast made a difference remember this\n",
    "        if (u_size > l_size):\n",
    "            lv += [index]\n",
    "    else:\n",
    "    #try numbers\n",
    "        num_vals = pd.Series(unique_vals).apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "        num_vals = num_vals.dropna()\n",
    "        \n",
    "        n_size = float(num_vals.size)\n",
    "        \n",
    "        #if the majority is numbers\n",
    "        if ((n_size / u_size) > 0.9):\n",
    "            nv += [index]\n",
    "        #well something else\n",
    "        else:\n",
    "            ov += [index]\n",
    "\n",
    "for i in range(1,117):\n",
    "    split_variables(i)            \n",
    "            \n",
    "print cat_var \n",
    "print lower_var\n",
    "print num_var\n",
    "print other_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def survey_column(index, data = df_sf, first_n = 20, bins = 50, force_num = False,\\\n",
    "                  cat = False, ratio = 2, min_p = 0.05, drop_p = 0.1,\\\n",
    "                  print_out = False, draw_hist = False, print_uvals = False):\n",
    "    \n",
    "    name = data[0].columns[index]\n",
    "    \n",
    "    if print_out:\n",
    "        print str(index)+\" \"+ name\n",
    "    \n",
    "    s_col = data[0].iloc[:,index]\n",
    "    f_col = data[1].iloc[:,index]\n",
    "    \n",
    "    s_size = s_col.size\n",
    "    f_size = f_col.size\n",
    "    \n",
    "    #show first size rows\n",
    "    ccol_df = pd.concat([s_col.iloc[0:first_n,],f_col.iloc[0:first_n,]], axis =1)\n",
    "    #rename columns\n",
    "    ccol_df.columns =[\"S:\"+name,\"F:\"+name]\n",
    "    \n",
    "    if print_out:\n",
    "        display(ccol_df)\n",
    "\n",
    "    s_col = s_col.dropna()\n",
    "    f_col = f_col.dropna()\n",
    "    \n",
    "    if (cat):\n",
    "        unique_vals = np.append(s_col.unique(),f_col.unique())\n",
    "        unique_vals = np.unique(unique_vals)\n",
    "        unique_vals = np.sort(unique_vals)\n",
    "        \n",
    "        # print out first nr_vals\n",
    "        if print_out:\n",
    "            if unique_vals.size > first_n:\n",
    "                print unique_vals[0:first_n]\n",
    "        elif print_uvals:\n",
    "            print str(index)+\" \"+ name\n",
    "            print unique_vals\n",
    "                \n",
    "        #cast categories into indexes\n",
    "        s_col = s_col.apply(lambda x: np.searchsorted(unique_vals,x))\n",
    "        f_col = f_col.apply(lambda x: np.searchsorted(unique_vals,x))\n",
    "\n",
    "\n",
    "    #force casting into numbers\n",
    "    elif force_num:\n",
    "        s_col = s_col.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "        f_col = f_col.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "  \n",
    "        s_col = s_col.dropna()\n",
    "        f_col = f_col.dropna()\n",
    "        \n",
    "    \n",
    "    s_dropped =(s_size-s_col.size)/float(s_size)\n",
    "    f_dropped =(f_size-f_col.size)/float(f_size)\n",
    "    \n",
    "    if print_out:\n",
    "        print \"Dropped values S/F: {0:2.2f}% / {1:2.2f}%\".format(s_dropped*100, f_dropped*100)\n",
    "    \n",
    "    #do df summaries\n",
    "    \n",
    "    cdes_df = pd.concat([s_col.describe(),f_col.describe()], axis =1)\n",
    "    #rename columns\n",
    "    cdes_df.columns =[\"S:\"+name,\"F:\"+name]\n",
    "    \n",
    "    #count how many values there were before preprocessing (before removing weird valeus)\n",
    "    f_line = pd.DataFrame({\"S:\"+name: [len(success_df.index)],\"F:\"+name:[len(failed_df.index)]}, index = [\"t_count\"])\n",
    "    \n",
    "    #prepend fline\n",
    "    cdes_df = pd.concat([f_line,cdes_df])\n",
    "    \n",
    "    if print_out:\n",
    "        display(cdes_df)\n",
    "\n",
    "    #get histograms with categorical variables # bins = # categories\n",
    "    if (cat):\n",
    "        b, nh_s, nh_f =normalize_double_hist((s_col,f_col),\\\n",
    "                                       bins = unique_vals.size)\n",
    "    else:\n",
    "        b, nh_s, nh_f =normalize_double_hist((s_col,f_col),\\\n",
    "                                       bins = bins)\n",
    "    \n",
    "    if draw_hist:\n",
    "        fig, ax = plt.subplots(2,2, figsize=(15,6))\n",
    "\n",
    "        max_hist = max (nh_s.max(), nh_f.max())\n",
    "\n",
    "        step = b[1] - b[0]\n",
    "\n",
    "        scale = 1.1\n",
    "\n",
    "        ax[0,0].bar(b[:-1], nh_s, width= step, color='green')    \n",
    "        ax[0,0].set_title(\"S:\"+name)\n",
    "        ax[0,0].set_xlim([b[0]*scale,b[-1]*scale])\n",
    "        ax[0,0].set_ylim([0,max_hist])\n",
    "\n",
    "        ax[0,1].bar(b[:-1], nh_f, width= step, color='red')\n",
    "        ax[0,1].set_title(\"F:\"+name)\n",
    "        ax[0,1].set_xlim([b[0]*scale,b[-1]*scale])\n",
    "        ax[0,1].set_ylim([0,max_hist*scale])\n",
    "\n",
    "        s_less = nh_s *(nh_s <= nh_f)\n",
    "        ax[1,0].bar(b[:-1], nh_s, width= step, color='green')\n",
    "        ax[1,0].bar(b[:-1], nh_f, width= step, color='red')\n",
    "        ax[1,0].bar(b[:-1], s_less, width= step, color='green')\n",
    "        ax[1,0].set_title(\"Both\")\n",
    "        ax[1,0].set_xlim([b[0]*scale,b[-1]*scale])\n",
    "        ax[1,0].set_ylim([0,max_hist*scale])\n",
    "\n",
    "#     alternative plotting\n",
    "#     s_diff = nh_s - nh_f\n",
    "#     ax[1,1].bar(b[:-1], s_diff, width= step, color='orange')\n",
    "#     ax[1,1].set_title(\"Diff\")\n",
    "#     ax[1,1].set_xlim([b[0]*scale,b[-1]*scale])\n",
    "#     ax[1,1].set_ylim([s_diff.min()*scale,s_diff.max()*scale])\n",
    "    \n",
    "#     s_more = (nh_s > nh_f)    \n",
    "#     f_less_val = s_more * nh_f;\n",
    "#     f_less_val_neg = f_less_val * -1;\n",
    "    \n",
    "    \n",
    "#     ax[1,1].bar(b[:-1], f_less_val_neg, width= step, color='blue')\n",
    "#     ax[1,1].set_ylim([min(s_diff.min(),f_less_val_neg.min())*scale,s_diff.max()*scale])\n",
    "    \n",
    "    \n",
    "    #calculate ratio between success and fialure\n",
    "    sf_ratio = nh_s/nh_f\n",
    "    # remove inf, inf nan\n",
    "    sf_ratio[np.logical_not(np.isfinite(sf_ratio))] = 0\n",
    "    \n",
    "    \n",
    "    #ignore entries below ratio\n",
    "    sf_ratio[(sf_ratio<ratio)] =  0\n",
    "    #ignore entries not frequent enough\n",
    "    sf_ratio[(nh_s <= min_p)] =  0\n",
    "    \n",
    "    #only sucessess, no fialures in the bin\n",
    "    s_pos = np.copy(nh_s)\n",
    "    \n",
    "    s_pos[nh_f !=0] = 0\n",
    "    # to small cut it off\n",
    "    s_pos[(nh_f ==0) & (nh_s <= min_p)] = 0\n",
    "    # seems significan keep it\n",
    "    s_pos[(nh_f ==0) & (nh_s > min_p)] = 1\n",
    "    \n",
    "    if draw_hist:    \n",
    "        if sf_ratio.sum()>0:\n",
    "            ax[1,1].bar(b[:-1], sf_ratio, width= step, color='blue')\n",
    "            ax[1,1].set_ylim([0,sf_ratio.max()*scale])\n",
    "        \n",
    "        if s_pos.sum()>0:\n",
    "        #this is scaled to ratio so it is always visible\n",
    "            ax[1,1].bar(b[:-1], s_pos*ratio, width= step, color='orange')\n",
    "\n",
    "        ax[1,1].set_title(\"S/F ratio above \"+str(ratio))\n",
    "        ax[1,1].set_xlim([b[0]*scale,b[-1]*scale])\n",
    "    \n",
    "    \n",
    "    #shorten the arraus and keep only significant values\n",
    "    short_ratio = np.copy(sf_ratio)\n",
    "    short_ratio = short_ratio[sf_ratio>=ratio]    \n",
    "    #-1 for sorting desc\n",
    "    short_ratio = np.sort(-1 *short_ratio)*-1\n",
    "    \n",
    "    #isnt dropout too much\n",
    "    drop_ok = ((f_dropped< drop_p) and (s_dropped< drop_p)) \n",
    "    \n",
    "    looks_good = False\n",
    "        \n",
    "    if (short_ratio.size> 0) and (drop_ok):\n",
    "        if (cat): #(cat and print_out):\n",
    "            print \"vals: \" + str(unique_vals[sf_ratio>=ratio])\n",
    "        \n",
    "        print \"ratio: \" + str(sf_ratio[sf_ratio>=ratio])\n",
    "        print \"suc: \" +str(nh_s[sf_ratio>=ratio])\n",
    "        \n",
    "        looks_good = True \n",
    "        print \"sorted ratio: \"+str(short_ratio)\n",
    "        print \"***\"\n",
    "            \n",
    "    #sort only the suc > min_p\n",
    "    only_suc = s_pos * nh_s\n",
    "    short_suc = np.copy(only_suc)\n",
    "    short_suc = short_suc[only_suc>0] \n",
    "    #-1 for sorting desc\n",
    "    short_suc = np.sort(-1 *short_suc)*-1\n",
    "    \n",
    "    if (short_suc.size>0) and (drop_ok):\n",
    "        if (cat): #(cat and print_out):\n",
    "            print \"val: \" +str(unique_vals[only_suc>0])\n",
    "        \n",
    "        print \"no_fail: \" +str(nh_s[only_suc>0])\n",
    "        \n",
    "        looks_good = True\n",
    "        print \"sorted no_fail: \" +str(short_suc)\n",
    "        print \"***\"\n",
    "        \n",
    "    \n",
    "    if looks_good:\n",
    "        print \"Dropped values S/F: {0:2.2f}% / {1:2.2f}%\".format(s_dropped*100, f_dropped*100)\n",
    "        print str(index)+\" \"+ name\n",
    "        if cat:\n",
    "            print unique_vals\n",
    "        \n",
    "    return looks_good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string_cols = [1, 6, 8]\n",
    "\n",
    "date_cols=[3, 13, 14]\n",
    " \n",
    "set_cols=[7, 9]\n",
    "\n",
    "boolean_cols=[2, 12, 24, 27, 29, 30, 31, 32, 34, 35, 38, 46, 47, 48, 49, 50, 51, 52, 53, 54,\\\n",
    "             55, 57, 58, 59, 63, 64, 68, 69, 70, 73, 77, 78, 81, 82, 83, 84, 85, 86, 89, 90,\\\n",
    "             91, 97]\n",
    "\n",
    "perc_cols = range(102,116)\n",
    "\n",
    "num_cols=[4, 5, 10, 11, 15, 18, 19, 20, 21, 22, 23, 25, 66, 72, 74, 88, 94, 95, 96, 98, 99,116]\n",
    "\n",
    "cat_cols=[16, 17, 26, 28, 33, 35, 37, 39, 40, 43, 44, 45, 54, 56, 57, 59, 60, 61, 62, 65,\\\n",
    "          67, 71, 73, 75, 76, 79, 80, 87, 92, 93, 100, 101]\n",
    "\n",
    "\n",
    "boolean_cols=[2, 12, 24, 27, 29, 30, 31, 32, 34, 36, 38, 41, 42, 46, 47, 48, 49, 50, 51,\\\n",
    "              52, 53, 55, 58, 63, 64, 68, 69, 70, 77, 78, 81, 82, 83, 84, 85, 86, 89,\\\n",
    "              90,91]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 12, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 97, 100, 101, 112, 116]\n",
      "[12, 26, 39, 40]\n",
      "[5, 10, 11, 15, 23, 66, 72, 74, 88, 94, 95, 96, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115]\n",
      "[1, 6, 7, 8, 9, 13, 14, 16, 62]\n"
     ]
    }
   ],
   "source": [
    "print cat_var \n",
    "print lower_var\n",
    "print num_var\n",
    "print other_var\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-b694a6f3a1e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mis_good\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mis_good\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurvey_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_var\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m                            \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m                            \u001b[0mprint_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_uvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mis_good\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# is_good = False\n",
    "# i_col = 0\n",
    "\n",
    "while(not is_good):\n",
    "    is_good = survey_column(cat_var[i_col], force_num = False, cat = True,\\\n",
    "                            ratio = 9.0, min_p = 0.20, drop_p = 0.2,\\\n",
    "                            print_out = False, draw_hist = False, print_uvals = False)\n",
    "    \n",
    "    if(not is_good):\n",
    "        i_col+=1\n",
    "        \n",
    "i_col+=1\n",
    "is_good = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-09680635030f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mis_good\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mis_good\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurvey_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_var\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m                            \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m                            \u001b[0mprint_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_uvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mis_good\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mi_col\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# is_good = False\n",
    "# i_col = 0\n",
    "\n",
    "while(not is_good):\n",
    "    is_good = survey_column(num_var[i_col], force_num = True, cat = False,\\\n",
    "                            ratio = 4.0, min_p = 0.05, drop_p = 0.5,\\\n",
    "                            print_out = False, draw_hist = False, print_uvals = True)\n",
    "    if(not is_good):\n",
    "        i_col+=1\n",
    "        \n",
    "i_col+=1\n",
    "is_good = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 115 (116? variables) for each company. Shockingly there are almost twice as many (305) sucessful companies as failed ones (167). This is of course *VERY SUSPICIOUS* and likely and indication of a synthetic data set. In real life most companies fail.\n",
    "\n",
    "This my also indicate that we might address the inverse problem, that is "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
